{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score,confusion_matrix, mean_absolute_error , r2_score , mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LeakyReLU,BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/cancer_patient.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].describe())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0: \"extremely low\",\n",
    "    1: \"very low\",\n",
    "    2: \"low\",\n",
    "    3: \"below medium average\",\n",
    "    4: \"medium\",\n",
    "    5: \"above medium average\",\n",
    "    6: \"high\",\n",
    "    7: \"very high\",\n",
    "    8: \"extremely high\",\n",
    "    9: \"Maximum\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Age Range in Data\")\n",
    "plt.bar(df['Age'], height=df.shape[0],width=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,4))\n",
    "sns.kdeplot(df.Age, shade = True, color = \"g\")\n",
    "plt.title(\"Age Count\", fontsize = 18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop([\"Level\",\"Patient Id\",\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (24, 24))\n",
    "sns.heatmap(df1.corr(), annot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationC=[]\n",
    "for col in df1.columns :\n",
    "    for column in df1.columns:\n",
    "        a = df1[col].corr(df1[column])\n",
    "        if a > 0.8 and (col != column) :\n",
    "            if a in correlationC:\n",
    "                continue\n",
    "            else :\n",
    "                correlationC.append(a)         \n",
    "                print (col +\" column has high correlation with column \"+ column)\n",
    "                print(df1[col].corr(df1[column]))\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationC.sort()\n",
    "correlationC.reverse()\n",
    "correlationC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df[\"Gender\"].replace([1,2],[\"Female\",\"Male\"])\n",
    "df[\"Air Pollution\"] = df[\"Air Pollution\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df[\"Dust Allergy\"] = df[\"Dust Allergy\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df[\"OccuPational Hazards\"] = df[\"OccuPational Hazards\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df[\"Genetic Risk\"] = df[\"Genetic Risk\"].replace([1,2,3,4,5,6,7],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]])\n",
    "df[\"chronic Lung Disease\"] = df[\"chronic Lung Disease\"].replace([1,2,3,4,5,6,7],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]])\n",
    "df[\"Fatigue\"] = df[\"Fatigue\"].replace([1,2,3,4,5,6,7,8,9],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8],labels[9]])\n",
    "df[\"Weight Loss\"] = df[\"Weight Loss\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df[\"Shortness of Breath\"] = df[\"Shortness of Breath\"].replace([1,2,3,4,5,6,7,8,9],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8],labels[9]])\n",
    "df[\"Wheezing\"] = df[\"Wheezing\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df[\"Swallowing Difficulty\"] = df[\"Swallowing Difficulty\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df[\"Clubbing of Finger Nails\"] = df[\"Clubbing of Finger Nails\"].replace([1,2,3,4,5,6,7,8,9],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8],labels[9]])\n",
    "df[\"Frequent Cold\"] = df[\"Frequent Cold\"].replace([1,2,3,4,5,6,7],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]])\n",
    "df[\"Dry Cough\"] = df[\"Dry Cough\"].replace([1,2,3,4,5,6,7],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]])\n",
    "df[\"Snoring\"] = df[\"Snoring\"].replace([1,2,3,4,5,6,7],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]])\n",
    "df[\"Obesity\"] = df[\"Obesity\"].replace([1,2,3,4,5,6,7],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7]])\n",
    "df[\"Passive Smoker\"] = df[\"Passive Smoker\"].replace([1,2,3,4,5,6,7,8],[labels[1],labels[2],labels[3],labels[4],labels[5],labels[6],labels[7],labels[8]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Passive Smoker\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,7))\n",
    "plt.title(\"Level Column Values\")\n",
    "round(df[\"Level\"].value_counts()/df.shape[0]*100,2).plot.pie(autopct= '%2.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Occupatinal Hazard and Genetic Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(18, 6))\n",
    "plt.xlabel(\"OccuPational Hazards\")\n",
    "plt.ylabel(\"Genetic Risk\")\n",
    "plt.title(\"Relation between OccuPational Hazards and Genetic Risk\")\n",
    "plt.scatter(df[\"OccuPational Hazards\"],df[\"Genetic Risk\"],alpha=0.7,c=\"red\",linewidths=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 7))\n",
    "\n",
    "sns.histplot(data=df, x=df[\"OccuPational Hazards\"], hue=df[\"Gender\"], multiple=\"dodge\", shrink=.8,palette=[\"red\",\"blue\"]).set(title='Relation Between OccuPational Hazards and Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smokers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 7))\n",
    "plt.title(\"Number of Passive Smokers\")\n",
    "sns.histplot(data=df, x=df[\"Passive Smoker\"],color= \"darkcyan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df.copy()\n",
    "\n",
    "df3['AgeRange'] = None\n",
    "df3.loc[(df3['Age'] > 14) & (df3[\"Age\"] < 18), 'AgeRange'] = \"Teenager\"\n",
    "df3.loc[(df3['Age'] > 18) & (df3[\"Age\"] < 45), 'AgeRange'] = \"Adult\"\n",
    "df3.loc[(df3['Age'] > 45) & (df3[\"Age\"] < 74), 'AgeRange'] = \"senile\"\n",
    "\n",
    "\n",
    "sns.catplot(data=df3, x=\"AgeRange\", y=\"Alcohol use\",aspect=20/10,height=5).set(title='Relation Between Age and Alcohol use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation Genetic Risk and chronic Lung Disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 7))\n",
    "\n",
    "plt.hist(df['Genetic Risk'], bins=25, alpha=0.45, color='red')\n",
    "plt.hist(df['chronic Lung Disease'], bins=50, alpha=0.45, color='blue')\n",
    "\n",
    "plt.title(\"Relation Genetic Risk and chronic Lung Disease \")\n",
    "\n",
    "  \n",
    "plt.legend(['Genetic Risk', 'chronic Lung Disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(\"./datasets/cancer_patient.csv\", sep=\",\",encoding=\"UTF-8\")\n",
    "\n",
    "plt.subplots(figsize=(20, 7))\n",
    "\n",
    "plt.hist(df6['Genetic Risk'], bins=25, alpha=0.45, color='red')\n",
    "plt.hist(df6['chronic Lung Disease'], bins=50, alpha=0.45, color='blue')\n",
    "\n",
    "plt.title(\"Relation Genetic Risk and chronic Lung Disease \")\n",
    "  \n",
    "plt.legend(['Genetic Risk', \n",
    "            'chronic Lung Disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(18, 6))\n",
    "plt.xlabel(\"OccuPational Hazards\")\n",
    "plt.ylabel(\"Genetic Risk\")\n",
    "plt.title(\"Relation between OccuPational Hazards and Genetic Risk\")\n",
    "plt.scatter(df6[\"OccuPational Hazards\"],df6[\"Genetic Risk\"],alpha=0.7,c=\"blue\",linewidths=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Obesity and Coughing of Blood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.title(\"Relation between Obesity and Coughing of Blood\")\n",
    "sns.barplot(data=df, x=\"Obesity\", y=\"Coughing of Blood\",palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.title(\"Relation between Obesity and Coughing of Blood\")\n",
    "sns.barplot(data=df6, x=\"Obesity\", y=\"Coughing of Blood\",palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.plot(kind='box', subplots=True, layout=(5,5), figsize=(18,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Age Column Box Plot\")\n",
    "sns.boxenplot(x=df.Age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# transforming the datatype\n",
    "df6['Level'] = le.fit_transform(df6['Level'])\n",
    "df6['Patient Id'] = le.fit_transform(df6['Patient Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df6.drop([\"Level\",\"Patient Id\",\"index\"],axis=1).values\n",
    "y = df.Level.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scaler = StandardScaler().fit(x_train)\n",
    "x_train_scaled = s_scaler.transform(x_train)\n",
    "x_test_scaled = s_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultsSummarizer(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    sns.heatmap(cm,\n",
    "                annot=True,\n",
    "                cmap='Blues',\n",
    "                xticklabels=labels.values(),\n",
    "                yticklabels=labels.values()\n",
    "               ) \n",
    "    \n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Activity')\n",
    "    plt.ylabel('Actual Activity')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Accuracy Score: ' + '{:.4%}'.format(acc))\n",
    "    print(f'Precision Score: ' + '{:.4%}'.format(prec))\n",
    "    print(f'Recall Score: ' + '{:.4%}'.format(rec))\n",
    "    print(f'F_1 Score: ' + '{:.4%}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(x_test)\n",
    "data=pd.DataFrame({'y_Test  ':y_test,'y_pred  ':y_pred})\n",
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6)) \n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn.predict(x_test)\n",
    "data=pd.DataFrame({'y_Test  ':y_test,'y_pred  ':y_pred})\n",
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(x_train_scaled, y_train)\n",
    "y_pred_knn = knn2.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSummarizer(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6)) \n",
    "cm=confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm,annot=True, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfst = RandomForestClassifier(n_estimators=10,random_state=42)\n",
    "rfst.fit(x_train_scaled, y_train)\n",
    "y_pred_rfst = rfst.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSummarizer(y_pred_rfst, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6)) \n",
    "cm=confusion_matrix(y_test, y_pred_rfst)\n",
    "sns.heatmap(cm,annot=True, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = 0.02*np.arange(1,20)\n",
    "gamma_grid = 0.02*np.arange(1,50)\n",
    "print(C_grid,gamma_grid)\n",
    "parameters = {'C': C_grid, 'gamma' : gamma_grid}\n",
    "gridCV = GridSearchCV(SVC(kernel='rbf'), parameters, n_jobs=-1)             \n",
    "gridCV.fit(x_train[:1000],y_train[:1000])\n",
    "best_C = gridCV.best_params_['C']\n",
    "best_gamma = gridCV.best_params_['gamma']\n",
    "\n",
    "print(\"Best C \"+str(best_C))\n",
    "print(\"Best Gamma \"+str(best_gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Kernel\n",
    "lin = SVC(kernel='linear',C=best_C,gamma=best_gamma)\n",
    "lin.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Linear = lin.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_Linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6)) \n",
    "cm=confusion_matrix(y_test, y_pred_Linear)\n",
    "sns.heatmap(cm,annot=True, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSummarizer(y_pred_Linear, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel\n",
    "rbf = SVC(kernel='rbf',C=1,gamma=0.6)\n",
    "rbf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_RBF = rbf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_RBF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6)) \n",
    "cm=confusion_matrix(y_test, y_pred_RBF)\n",
    "sns.heatmap(cm,annot=True, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resultsSummarizer(y_test, y_pred_RBF)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes\n",
    "### Gaussian Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_gnb = nb_model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Naive Bayes Performance Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "plt.figure(figsize=(7, 6)) \n",
    "cm=confusion_matrix(y_test, y_pred_gnb)\n",
    "sns.heatmap(cm,annot=True, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resultsSummarizer(y_pred_gnb, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize the Categorical Naive Bayes model\n",
    "nb_model_cat = CategoricalNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "nb_model_cat.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_cnb = nb_model_cat.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Categorical Naive Bayes Performance Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_cnb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(7, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_cnb)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Activity')\n",
    "plt.ylabel('Actual Activity')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resultsSummarizer(y_pred_cnb, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.read_csv(\"./datasets/cancer_patient.csv\", sep=\",\",encoding=\"UTF-8\")\n",
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.Level = df10.Level.replace(\"Low\", 0)\n",
    "df10.Level = df10.Level.replace(\"Medium\", 1)\n",
    "df10.Level = df10.Level.replace(\"High\", 2)\n",
    "df10.Level = df10.Level.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df10.drop([\"Level\",\"Patient Id\",\"index\"], axis = 1)\n",
    "y = pd.get_dummies(df[\"Level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation = \"relu\", input_dim = x.shape[1]))\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(8, activation = \"relu\"))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x, y, epochs = 50, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy of Data\")\n",
    "plt.plot(history.history[\"accuracy\"], label = \"Training accuracy\", marker = \"o\", color = \"darkblue\",)\n",
    "plt.plot(history.history[\"val_accuracy\"],label = \"Validation accuracy\", marker = \"o\",color = \"r\",)\n",
    "plt.title(\"Training VS Validation Accuracy\", fontsize = 18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss in Data\")\n",
    "plt.plot(history.history[\"loss\"], label= \"Training loss\", marker = \"o\", color = \"darkblue\",)\n",
    "plt.plot(history.history[\"val_loss\"], label= \"Validation loss\", marker = \"o\", color = \"r\",)\n",
    "plt.title(\"Training VS Validation loss\", fontsize = 18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.read_csv(\"./datasets/cancer_patient.csv\", sep=\",\",encoding=\"UTF-8\")\n",
    "df11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df11.drop(columns=['index', 'Patient Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df11['Level'] = le.fit_transform(df11['Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11 = df11.drop(columns=['Level'])\n",
    "Y11 = df11['Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "X11 = scaler1.fit_transform(X11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X11, Y11, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['index', 'Patient Id']\n",
    "    X = df.drop(columns_to_drop + ['Level'], axis=1)\n",
    "    \n",
    "    # Convert Gender to numeric if not already\n",
    "    X['Gender'] = X['Gender'].astype(int)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Encode the target variable\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df['Level'])\n",
    "    \n",
    "    return X_scaled, y, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    model = Sequential([\n",
    "        # Input layer\n",
    "        Dense(256, input_dim=input_dim, \n",
    "              kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Hidden layers\n",
    "        Dense(128, kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(64, kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with cross-validation\n",
    "def train_model(X, y, n_splits=5):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = compute_class_weight('balanced', \n",
    "                                       classes=np.unique(y), \n",
    "                                       y=y)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=7,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f'\\nFold {fold + 1}/{n_splits}')\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = create_model(X.shape[1])\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        score = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_scores.append(score[1])\n",
    "        print(f'Fold {fold + 1} Validation Accuracy: {score[1]:.4f}')\n",
    "    \n",
    "    print(f'\\nMean CV Accuracy: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})')\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.read_csv(\"./datasets/cancer_patient.csv\", sep=\",\",encoding=\"UTF-8\")\n",
    "\n",
    "X_scaled, y, label_encoder = preprocess_data(df11)\n",
    "model, history = train_model(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing set\n",
    "y1_pred = model.predict(X_test)\n",
    "y1_pred_classes = y1_pred.argmax(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSummarizer(y_test, y1_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_report = classification_report(y_test, y1_pred_classes)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy of Data\")\n",
    "plt.plot(history.history[\"accuracy\"], label = \"Training accuracy\", marker = \"o\", color = \"darkblue\",)\n",
    "plt.plot(history.history[\"val_accuracy\"],label = \"Validation accuracy\", marker = \"o\",color = \"r\",)\n",
    "plt.title(\"Training VS Validation Accuracy\", fontsize = 18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss in Data\")\n",
    "plt.plot(history.history[\"loss\"], label= \"Training loss\", marker = \"o\", color = \"darkblue\",)\n",
    "plt.plot(history.history[\"val_loss\"], label= \"Validation loss\", marker = \"o\", color = \"r\",)\n",
    "plt.title(\"Training VS Validation loss\", fontsize = 18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
